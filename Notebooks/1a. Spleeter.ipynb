{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12d9208",
   "metadata": {},
   "source": [
    "# Separating A Capella Songs into their Separated Vocal Tracks using Spleeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source credit: https://github.com/deezer/spleeter/wiki/2.-Getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef059c0cef5f168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T14:10:02.562433700Z",
     "start_time": "2023-10-30T14:09:59.504006100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0264e0b4196b90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T14:34:17.879879300Z",
     "start_time": "2023-10-30T14:34:16.854891200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get duration of a song\n",
    "def get_duration(filename):\n",
    "    y, sr = librosa.load(filename)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    return duration\n",
    "\n",
    "# Add to csv file\n",
    "def add_to_csv(mix_path, alto_path, bass_path, lead_vocal_path, soprano_path, tenor_path, vocal_percussion_path, csv_path):\n",
    "    # print(\"adding\")\n",
    "    duration = get_duration(mix_path)\n",
    "    with open(csv_path, 'a') as f:\n",
    "        f.write(mix_path + ',' + alto_path + ',' + bass_path + ',' + lead_vocal_path + ',' + soprano_path + ',' + tenor_path + ',' + vocal_percussion_path + ',' + str(duration) + '\\n')\n",
    "\n",
    "# Put audio tracks from dataset into training csv file\n",
    "def create_training_file():\n",
    "    for genre in [filename for filename in os.listdir('Dataset/Jacapella') if os.path.isdir(os.path.join('Dataset/Jacapella',filename))]:\n",
    "        for song in [filename for filename in os.listdir('Dataset/Jacapella/'+genre) if os.path.isdir(os.path.join('Dataset/Jacapella/'+genre,filename))]:\n",
    "            mix_path = 'Dataset/Jacapella/' + genre + '/' + song + '/mixture.wav'\n",
    "            alto_path = 'Dataset/Jacapella/' + genre + '/' + song + '/alto.wav'\n",
    "            bass_path = 'Dataset/Jacapella/' + genre + '/' + song + '/bass.wav'\n",
    "            lead_vocal_path = 'Dataset/Jacapella/' + genre + '/' + song + '/lead_vocal.wav'\n",
    "            soprano_path = 'Dataset/Jacapella/' + genre + '/' + song + '/soprano.wav'\n",
    "            tenor_path = 'Dataset/Jacapella/' + genre + '/' + song + '/tenor.wav'\n",
    "            vocal_percussion_path = 'Dataset/Jacapella/' + genre + '/' + song + '/vocal_percussion.wav'\n",
    "            add_to_csv(mix_path, alto_path, bass_path, lead_vocal_path, soprano_path, tenor_path, vocal_percussion_path, 'configs/jacapella_train.csv')\n",
    "    print(\"Training file created\") \n",
    "\n",
    "# sample 5 random songs from training csv to validation csv\n",
    "def create_validation_file():\n",
    "    with open('configs/jacapella_train.csv', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        random.shuffle(lines)\n",
    "        for line in lines[:5]:\n",
    "            with open('configs/jacapella_validation.csv', 'a') as f:\n",
    "                f.write(line)\n",
    "            # remove those lines from training csv\n",
    "            lines.remove(line)\n",
    "    print(\"Validation file created\")\n",
    "\n",
    "# def create_testing_file():\n",
    "#     with open('configs/jacapella_train.csv', 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#         random.shuffle(lines)\n",
    "#         for line in lines[:5]:\n",
    "#             with open('configs/jacapella_test.csv', 'a') as f:\n",
    "#                 f.write(line)\n",
    "#             # remove those lines from training csv\n",
    "#             lines.remove(line)\n",
    "#     print(\"Testing file created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366e79b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file created\n",
      "Validation file created\n",
      "INFO:spleeter:Start model training\n",
      "Audio separation trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\Scripts\\spleeter.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\__main__.py\", line 267, in entrypoint\n",
      "    spleeter()\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\typer\\main.py\", line 214, in __call__\n",
      "    return get_command(self)(*args, **kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\click\\core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\click\\core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1259, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\click\\core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\click\\core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\typer\\main.py\", line 497, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\__main__.py\", line 104, in train\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, evaluation_spec)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 504, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 645, in run\n",
      "    return self.run_local()\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py\", line 742, in run_local\n",
      "    self._estimator.train(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1212, in _train_model_default\n",
      "    self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1048, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1141, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\dataset.py\", line 85, in get_training_dataset\n",
      "    return builder.build(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\dataset.py\", line 532, in build\n",
      "    dataset = self.compute_segments(dataset, n_chunks_per_song)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\dataset.py\", line 438, in compute_segments\n",
      "    dataset.map(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2048, in map\n",
      "    return MapDataset(self, map_func, preserve_cardinality=True, name=name)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 5243, in __init__\n",
      "    self._map_func = structured_function.StructuredFunctionWrapper(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 271, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2567, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2533, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2711, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2627, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1141, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 248, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\", line 177, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 692, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 689, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"C:\\Users\\65900\\AppData\\Local\\Temp\\__autograph_generated_file3l2yng_c.py\", line 8, in <lambda>\n",
      "    tf__lam = lambda sample: ag__.with_function_scope(lambda lscope: ag__.converted_call(dict, (sample,), dict(start=ag__.converted_call(tf.maximum, (k * (sample['duration'] - self._chunk_duration - 2 * self.MARGIN) / (n_chunks_per_song - 1) + self.MARGIN, 0), None, lscope)), lscope), 'lscope', ag__.STD)\n",
      "  File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py\", line 113, in with_function_scope\n",
      "    return thunk(scope)\n",
      "  File \"C:\\Users\\65900\\AppData\\Local\\Temp\\__autograph_generated_file3l2yng_c.py\", line 8, in <lambda>\n",
      "    tf__lam = lambda sample: ag__.with_function_scope(lambda lscope: ag__.converted_call(dict, (sample,), dict(start=ag__.converted_call(tf.maximum, (k * (sample['duration'] - self._chunk_duration - 2 * self.MARGIN) / (n_chunks_per_song - 1) + self.MARGIN, 0), None, lscope)), lscope), 'lscope', ag__.STD)\n",
      "tensorflow.python.autograph.pyct.error_utils.MultilineMessageKeyError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\65900\\anaconda3\\lib\\site-packages\\spleeter\\dataset.py\", line 439, in None  *\n",
      "        )\n",
      "\n",
      "    KeyError: 'duration'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Spleeter\n",
    "def audio_train_spleeter():\n",
    "    create_training_file()\n",
    "    create_validation_file()\n",
    "    !spleeter train -p configs/jacapella_config.json -d '/'\n",
    "    print(\"Audio separation trained\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_train_spleeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spleeter separate -p configs/jacapella_config.json -o output Dataset/Jacapella/Pop/1/mixture.wav"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
